{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4600f86a-b35a-4dfb-8757-3f6f6031c1ed",
   "metadata": {},
   "source": [
    "# Portfolio part 4 (workbook 8) Self-Checker\n",
    "\n",
    "This notebook is designed to stream line the process of checking and improving \n",
    "the two assessed activities from workbook 8.\n",
    "\n",
    "It is specifically designed to:\n",
    "- reduce frustration that happens when the marking system rejects or will not run your code.\n",
    "- maximise your opportunities for getting useful feedback  \n",
    "\n",
    "We **strongly recommend** that you use this to test your code prior to submission rather than waste any attempts on code that would fail to run on the marking server.\n",
    "\n",
    "## How to use:\n",
    "- work through this notebook making sure you run all the cells\n",
    "- it will import the code you produced from the workbook\n",
    "- afterwards cells will import your code back into the notebook and run the same code that is present on the marking server.\n",
    "\n",
    "- **Please note:  Although the code is the same, the datasets used to test your workflow may be different on the marking server**\n",
    "\n",
    "### When you are happy with your work, we recommend that you\n",
    "1. Select  'kernel-> restart kernel and clear all outputs' from the top menu\n",
    "2. Run all the cells in order, making sure all the outputs are ok.\n",
    "3. Download the file student_wb8.py ready for submission.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaea699-66a4-4d14-9226-c6f7342f9f9c",
   "metadata": {},
   "source": [
    "### Run next cell to set up code imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa89e46-8409-40e4-a33e-4cf302f15715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import your code\n",
    "from sys import path\n",
    "\n",
    "# telling python where to find the checking code things\n",
    "for directory in (\"../common\", \"studentcode\"):\n",
    "    if directory not in path:\n",
    "        path.append(directory)\n",
    "\n",
    "# functions common to all these notebooks\n",
    "import importcheck \n",
    "from bannedwords import check_for_banned_words\n",
    "\n",
    "# things specific to this notebook\n",
    "from approvedimports import *\n",
    "from wb8_selfcheck import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df03a8-e245-4b7f-adfe-c8d9972ad662",
   "metadata": {},
   "source": [
    "## Run this cell to check for syntax errors that could prevent your code from being imported \n",
    "<div style=\"background:lightblue\"><h3>There's no point moving on until your code passes this check.</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ad567-4238-481c-81f5-0b16785c862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok, message = importcheck.check_code_syntax(\"student_wb8\")\n",
    "if(ok):\n",
    "    print('Syntax seems to be ok')\n",
    "else:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7565cf5-10c2-4ed7-b80c-555539eff14d",
   "metadata": {},
   "source": [
    "## Run this cell to check all the required functions are present in your file\n",
    "- This cell will check whether your code contains all the required functions.\n",
    "\n",
    "- You may, if you wish, submit without attempting all the marked activities.\n",
    "\n",
    "- However, ** those functions need to be present**.\n",
    "\n",
    "- So you still need to run the cells that write the incomplete *boilerplate* code to your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16604fd3-0750-41ac-beed-9b2b3e1986f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs= ['make_xor_reliability_plot', \n",
    "        'MLComparisonWorkflow'\n",
    "       ]\n",
    "\n",
    "for funcname in funcs:\n",
    "    ok, message=importcheck.test_for_presence('student_wb8',funcname)\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd0ba06-5fcd-4063-b647-e3cfd52ae073",
   "metadata": {},
   "source": [
    "## Run the next cell to check for banned words\n",
    "<div style=\"background:lightpink\"><h3>The System will refuse to accept your code if banned words are present</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec025c15-e627-4060-b8e2-21e68f7bdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_banned_words(\"studentcode/student_wb8.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f0f6e-f140-41fc-9673-6d9a8a799530",
   "metadata": {},
   "source": [
    "## Testing activity 1.1: Evaluating Reliability and efficiency as network size grows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007a0eb-a00e-46cb-90e7-05d0730b68a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\" style=\"color:black\">\n",
    " <h2> Activity 1.2 (Assessed) <br>Automating the investigation of the effect of model <i>capacity</i> on learning behaviour</h2>\n",
    "    <h3> 20 Marks:</h3>\n",
    "    <ul>\n",
    "        <li>0 marks if the code cell with the function <code>make_reliability_plot()</code> contains any text outside the function body</li>\n",
    "        <li> 0 marks if your code does not return the fig and axes objects as required</li> \n",
    "    <li>10 marks for producing a matplotlib figure containing two matplotlib ax objects with titles and labels as specified below,<br>\n",
    "    and returning the objects (i.e. a figure and an array of axes) </li>\n",
    "    <li> 5 marks each if the contents of the plots match the <i>reference version</i>.<br> This means you <b>must</b> set the <i>random_state</i> hyperparameter for each run as described below</li>\n",
    "    </ul>  \n",
    "<p></p>\n",
    "\n",
    "<h3>Task definition:</h3> Complete the function in  the  cell below to <i>automate</i> the process of investigating the effect of the model <i>capacity</i> (as controlled by <i>hidden_layer_sizes</i> hyper-parameter) for a MLP with a single layer of hidden nodes on:\n",
    "<ul> <li>the <i>reliability</i> - as measured by the <i> success rate</i> i.e. the proportion of runs that achieve 100% training accuracy</li>\n",
    "<li>  the <i> efficiency</i> - the mean number of training epochs per successful run.<br>\n",
    "    Note that to avoid <i>divide-by-zero</i> problems you should check if no runs are successful for a given value and report a value of 1000 in that case.  </li>\n",
    "    </ul>\n",
    "<p>What should be in the plots?</p>\n",
    "<ul>\n",
    "    <li> You must return two objects <i>fig</i> and <i>axs</i> produced by a call to <code>plt.subplots(1,2)</code></li>\n",
    "    <li> The left hand plot should have a title \"Reliability\", y-axis label \"Success Rate\" and x-axis label \"Hidden Layer Width\".</li>\n",
    "    <li> The right hand plot should have a title \"Efficiency\", y-axis label \"Mean epochs\" and x-axis label \"Hidden Layer Width\".</li>\n",
    "    <li> In both cases the width of the single hidden layer should cover the range 1,10 (inclusive) in steps of 1</li>\n",
    "    <li> Each plot should contain an appropriate line illustrating the results of the experiment</li> \n",
    "</ul>    \n",
    "<h3>How to go about the task</h3> \n",
    "    <p> In several of the stages below you will be adapting code from activity 1.1 and 'steps' refer to comments  and code snippets in that code cell.</p>\n",
    "<ol>\n",
    "    <li> Declare a list <code>hidden_layer_width</code> holding the values 1 to 10 (inclusive) defining the model size.</li>\n",
    "    <li> Declare a 1-d numpy array filled with zeros  called <code>successes</code> to hold the number of successful runs for the different model sizes.</li>\n",
    "    <li> Declare a 2-D numpy array filled with zeros of shape (10,10) called <code>epochs</code> \n",
    "    <li> Create two nested loops: one over all the values for a variable <code>h_nodes</code> from the list <code>hidden_layer_width</code> <br> and the other for a variable <code>repetition</code> between 0 and 9 (i.e. doing 10 repetitions).</li>\n",
    "    <li> Inside those loops \n",
    "        <ol>\n",
    "        <li>Copy and edit code from  step 3 from the first cell to create an MLP with one hidden layer containing the <i>h_nodes</i> nodes. <br><b>Make sure</b> that in the call  you set the parameter <i>random_state</i> to be the run index so the results are the same as mine.  </li>\n",
    "        <li>Copy and edit code from step 4 to  <i>fit</i> the model to the training data, </li>\n",
    "        <li>Copy and edit code from Step 5 to measure it's accuracy</li>\n",
    "            <li> If the accuracy is 100%:<ul>\n",
    "                <li><i>increment</i> the count  in  cell  <code>successes[hnodes]</code></li>\n",
    "            <li> store the number of epochs taken in the cell of the array <code>epochs[h_nodes][repetition]</code>.</li>\n",
    "            </ul>\n",
    "        </ol>\n",
    "    <li> Create a new array with one entry for each number of hidden nodes tested, that contains either:\n",
    "        <ul>\n",
    "            <li> 1000 if no runs got 100% accuracy for that network size</li>\n",
    "            <li> The mean number of epochs taken per successful run for that network size</li>\n",
    "        </ul>\n",
    "    <li>Copy and edit the code from step 6 in Activity 1.1 to make a figure contain two plots side-by-side as described in the task definition, set appropriate axis labels and title labels, and return the fig and axs objects </li>\n",
    "</ol>\n",
    "    <h3> Checklist before submission</h3>\n",
    "    <ul>\n",
    "    <li> The second cell below will let you test your code works before submission. </li>\n",
    "        <li> The marking server will reject your submission if there is any text or code  in the second cell that it outside inside the function definition.</li>\n",
    "        <li> Your function <b>must</b> return two things: the fig object, and the axs object (which should be an array of axes with shape (1,2).</li>\n",
    "     </ul>\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ee2d0-4301-485e-8757-5e171a90874e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create XOR data\n",
    "import numpy as np\n",
    "xor_x= np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "xor_y = np.array([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5246de71-b8cd-4b18-bea6-0433588fc3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    \n",
    "# load latest version of your code\n",
    "from importlib import reload\n",
    "import student_wb8 \n",
    "reload(student_wb8)\n",
    "from student_wb8 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c71f2-9151-4f55-bd11-b2f5a87a997b",
   "metadata": {},
   "source": [
    "### Next cell calls code that duplicates what is on the marking server\n",
    "Run it to see what mark you should get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740c2a6-9176-4ac0-ab9b-6d0c31760e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wb8_selfcheck import test_make_xor_reliability_plot\n",
    "#get rid of pre-existing variables to make sure behaviour mimics marking server\n",
    "if 'myfig' in globals():\n",
    "    del(myfig)\n",
    "if 'myaxs' in globals():\n",
    "    del(myaxs)\n",
    "\n",
    "\n",
    "try:\n",
    "    myfig,myaxs = make_xor_reliability_plot(xor_x,xor_y)\n",
    "    score, feedback= test_make_xor_reliability_plot(myfig,myaxs)\n",
    "    print(f'Score {score}\\n{feedback}')\n",
    "\n",
    "except Exception as e:\n",
    "    print ( \"method did not return two objects (fig and axs) as required.\\n\"\n",
    "               f' {e}\\n'\n",
    "               \"Fix this before trying to get a mark\"\n",
    "              )\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488b65b-c8d0-4905-b8f8-8692c1f43364",
   "metadata": {},
   "source": [
    "## Testing activity 3:\n",
    "### Creating a test workflow to fairly assess three different supervised learning algorithms on a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb92db-5d29-450e-9c67-8fd9479614a6",
   "metadata": {},
   "source": [
    "## Hints:\n",
    "1. This page [sklearn user guide on scaling](https://scikit-learn.org/stable/modules/preprocessing.html#) gives a good overview on how to scale data.\n",
    "- I recommend you use a MinmaxScaler \n",
    "- Remember that the idea of splitting data into train and test is to simulate what will happen once the model is deployed and encounters data it has never seen before.\n",
    "- That means you must fit the scaler to the training data (not all the data) i.e. do you train-test-split first\n",
    "\n",
    "2. If there a re more than two unqie labels present you will need to create  a onehot encoding of them to use with the MLP.\n",
    "- sklearn provides a LabelBinarizer class to do this [Description of how to use labelbinarizers](https://scikit-learn.org/stable/modules/preprocessing_targets.html#labelbinarizer) \n",
    "- Doing it using this class is *safest* because it makes the fewest assumptions about the labels (i.e. it can cope with labels that are [0,2,5] as well as  [0,1,2]) \n",
    "\n",
    "3. If you want to be really *pythonic* you can use the zip function for the hyper-parameter tuning,  \n",
    "   but for simplicity, for all three classifiers its easiest to make a list of values for each of the parameters you are asked to tune and then  use nested loops to iterate over them  \n",
    "- so if algorithm X has two params A and B you could make  lists ``` a_values =  [a1,a2,a3], b_values= [b1,b2]```  \n",
    "  and then do  \n",
    "```` \n",
    "  for aval in a_values:\n",
    "      for bval in b_values:\n",
    "         nextclassifier = X(paramA=aval,paramB=bval)\n",
    "         ....\n",
    "````\n",
    "    \n",
    "\n",
    "4. To make life easier, in my version of the MLP I created a set of tuples holding the hiden layer sizes to iterate over\n",
    "```layers= [(2,),(5,),(10,),(2,2),(5,2),(10,2),(2,5),(5,5),(10,5)] ```\n",
    "\n",
    "5. All of these sklearn version of classifiers support:\n",
    "- a *fit()* method (that your code should call with parameters  ```self.train_x``` and ```train_y``` and \n",
    "- a *score()* method, that returns a float (accuracy)  that your code should call with parameters ```self.test_x``` and ```test_y```   \n",
    "  where ```train_y, test_y``` are the *raw* or one_hot encoded versions of the labels depending on the classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf68437-b888-40e0-bb68-30c26717718e",
   "metadata": {},
   "source": [
    "### Run the next two cells to test your code prior to submission\n",
    "- the first cell defines the test function\n",
    "- the second one calls this test function using the iris data to test your code\n",
    "- **Note** on the marking server I may use a different dataset\n",
    "- so your code should not assume anything about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce38fb-1a4e-4a82-8f6e-b8211d154a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wb8_selfcheck\n",
    "reload(wb8_selfcheck)\n",
    "from wb8_selfcheck import test_mlcomparisonworkflow\n",
    "\n",
    "# load latest version of your code\n",
    "from importlib import reload\n",
    "import student_wb8 \n",
    "reload(student_wb8)\n",
    "from student_wb8 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a56ec7-6da8-494c-9c93-19f4fc1269f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use iris data for this pre-submission test\n",
    "from sklearn.datasets import load_iris\n",
    "iris_x, iris_y = load_iris(return_X_y=True)\n",
    "\n",
    "\n",
    "\n",
    "#call the test method, passing it your implementation of the workflow class\n",
    "score,feedback =test_mlcomparisonworkflow(MLComparisonWorkflow,iris_x,iris_y)\n",
    "print(f'*** For this dataset your code gets an indicative score of {score}, with this feedback:*****\\n'\n",
    "     f'{feedback}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c35f9-6fe6-4105-a2d3-71342324af97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
