{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Artificial Intelligence Ethics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Week:\n",
    "###  Background\n",
    "- What is ML: recap\n",
    "- Types of ML\n",
    "- Ethical Considerations\n",
    "- Creating and Using Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap:<img style=\"float:right\" width=300 src=\"./figures/basic-model-fitting.png\">\n",
    "- Machine Learning is:\n",
    " - the application of inductive logic to a dataset\n",
    " -  to create useful predictive models.  \n",
    " - So it is about solving  modelling problems\n",
    " - Machine Learning is about how you **automatically** create models  from data (inputs and outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Other types of AI where ethical issues apply\n",
    "- Expert Systems, where engineers  **manually** create models encoding human expertise\n",
    "  - this requires interviewing people to capture what they think is relevant\n",
    "  - then interpreting the interview notes\n",
    "  \n",
    "- Optimisation / Reinforcement Learning: have we specified the fitness/reward appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So it’s all about the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Yes!\n",
    "\n",
    "The aim is to build ML systems that can be used to do things when data or scenarios arise.  \n",
    "So we need data to: \n",
    "- train them on,  \n",
    "- choose between models, \n",
    "- Know (estimate) how well they are going to do when we start using them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We may not always have an output for every input \n",
    "- Because they’re not possible to capture\n",
    "  - e.g. data from scientific experiments such as genomics, astrophysics,...\n",
    "- Because sometimes we have to wait a while e.g.,\n",
    "  - game playing\n",
    "  - finding human volunteers to label images/ caption videos,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of Machine Learning\n",
    "Type | Inputs | Outputs | Feedback | What drives search? | Examples\n",
    "-----|--------|---------|----------------|---------------------|---------------------\n",
    "**Supervised** | Data |Predictions for each case | Correct labels | Accuracy of predictions made | **Recognition**  speech, images, actions, **Forecasting**\n",
    "**Reinforcement**| Scenarios | Actions to take in different states | Periodic Rewards | Expected future feedback | Learning game strategy\n",
    "**Unsupervised** | Data| Groupings of similar items | None | Statistics about cluster *coherence* and separation | Recommender systems, search engines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ethics: *Can* we use the data?\n",
    "- GDPR,  Privacy policies affect how it is collected\n",
    "- The law is very clear that we have to give people the right to:\n",
    "  - Provide Informed Consent about  how we are going to use their personal data at the time we collect it\n",
    "  - Find out what information we hold about them\n",
    "  - Withdraw their data (e.g. “right to forget”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of unethical use:    \n",
    " - Cambridge Analytica,   \n",
    " - targeting of fake news, propaganda on social media\n",
    "\n",
    "- Nowadays there should be clear collaboration agreements describing who is the data controller and who is the data processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ethics: *Should* we use the data? <img src=\"figures/algorithms-of-oppression.png\" style=\"float:right\" width = 100> \n",
    "<img style=\"float:right\" src=\"figures/protected-characteristics.png\" width = 500>\n",
    "\n",
    "- ML is only as good as the data we give it\n",
    "- So we have to be very careful that the data is representative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Examples of problems:\n",
    "  - Microsoft's (abandoned) Tay Bot\n",
    "  -     <a href=\"https://aibusiness.com/document.asp?doc_id=767688\">Google to remove gender labels from image recognition tool 25/2/21</a>\n",
    "  - <a href=\"https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/\">Predictive policing algorithms are racist. They need to be dismantled.</a>\n",
    "  -  <a href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G\">Amazon scraps secret AI recruiting tool that showed bias against women</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quick Video from Cog-x\n",
    "\n",
    "[![AI Ethics with Dong Nguyen, The Alan Turing Institute | CogX17 Highlight | CogX](https://img.youtube.com/vi/v=M-ko82Y0GUQ/0.jpg)](https://www.youtube.com/watch?v=M-ko82Y0GUQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So what can we do about it?\n",
    "\n",
    "## Data capture, storage and management\n",
    "1. Design data management plan\n",
    "2. Identify participants\n",
    "3. Inform participants\n",
    "4. Secure pseudonymised storage\n",
    " - for how long?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Research should be  FAIR\n",
    "  - findable\n",
    "  - accessible\n",
    "  - interoperable\n",
    "  - reuse of digital assets\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AI Research should be \"FAT\" \n",
    "- Fair\n",
    "- Accountable\n",
    "- Trustworthy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assessing Bias\n",
    "- just becuase you **can** capture an attribute, **should** you use it?\n",
    "- assessing impacts of attribute that represent PII?\n",
    " - permutation testing?\n",
    " - data augmentation?\n",
    " -  reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Environments for working with sensitive data\n",
    "<img src=\"figures/tre.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of controls for tradtional outputs\n",
    "\n",
    "### Threshold - *k*-anonymity: for counts and magnitude data\n",
    "- suppress table cells with less than *k* respondents\n",
    "\n",
    "### Dominance (for magnitude data):\n",
    "\n",
    "- nk: e.g. top two respondents account for less than 70% of total\n",
    "- p%  e.g. second biggest  can't guess biggest to within +/- p%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Risks for ML\n",
    "\n",
    "### Membership inference attacks\n",
    "- given a trained model,  and a record, \n",
    "- can we accurately predict whether record was in training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attribute Inference attacks\n",
    "- given a trained model and a partial record, \n",
    "- can we figure out what the values ofthe missing attributes were?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Controls for ML\n",
    "1: Differential privacy e.g. tensorflow privacy\n",
    "- add noise to update signals during training to reduce impact of any given trainig item\n",
    "\n",
    "2. Graimatter project (2022)\n",
    "- Unis.Dundee, UWE, Durham, NHS Scotland\n",
    "- funded by UKRI/ Health Data Research UK / DARE\n",
    "- developed recommendations for policy and best practice to help TREs make ML available to researchers\n",
    "- developed practical toolkits: \"safe model wrappers\" that:\n",
    " -- enforce good choices of ML hyper-parameters\n",
    " -- prodice automated reports for TRE output checking staff "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a href=\"https://dareuk.org.uk/sprint-exemplar-project-graimatter\">GRaimatter</a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
